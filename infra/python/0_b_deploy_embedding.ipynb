{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying an embedding model with Model-As-Service Serverless\n",
    "\n",
    "This notebook shows how to deploy an embedding model serverless on Azure AI Model-As-Service using the Python SDK.\n",
    "\n",
    "You can also bring your own embedding model or deploy it manually using either [Azure ML Studio](https://aka.ms/raft-llama-31-learn-deploy-405b) or [Azure AI Studio](https://aka.ms/raft-llama-31-learn-deploy-405b-ai-studio).\n",
    "\n",
    "**Note**: an Azure ML Workspace is the same as a Azure AI Hub, you will be able to go back and forth between the two transparently.\n",
    "\n",
    "If you choose to bring your own embedding model or deploy it manually, you can set the following environment variable in `.env`, this notebook will then skip deployment. You can also skip this notebook entirely, but note that the last cell in this notebook checks that the endpoint is up and running.\n",
    "\n",
    "```\n",
    "EMBEDDING_AZURE_OPENAI_ENDPOINT=<BASE_URL>\n",
    "EMBEDDING_AZURE_OPENAI_API_KEY=<API_KEY>\n",
    "EMBEDDING_AZURE_OPENAI_DEPLOYMENT=<DEPLOYMENT>\n",
    "```\n",
    "\n",
    "#### Model\n",
    "We will use `text-embedding-ada-002` as the embedding model to generate the RAFT synthetic dataset.\n",
    "\n",
    "#### Pre-requisites\n",
    "- Authenticate to Azure using `az login --use-device-code`\n",
    "- Existing workspace `config.json` file, either created by the previous `0_a_workspace.ipynb` notebook or brought over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "from azure.ai.ml.entities import MarketplaceSubscription, ServerlessEndpoint\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    client = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    print(\"Please create a workspace configuration file in the current directory.\")\n",
    "\n",
    "# Get AzureML workspace object.\n",
    "workspace = client._workspaces.get(client.workspace_name)\n",
    "workspace_id = workspace._workspace_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Meta Llama 3.1 405B Instruct as the teacher model to generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "teacher_embedding_model_name: str = \"text-embedding-ada-002\"\n",
    "embedding_registry_name: str = \"azure-openai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_ml_client = MLClient(credential, registry_name=embedding_registry_name)\n",
    "\n",
    "print(f\"Searching for model {teacher_embedding_model_name}\")\n",
    "model = registry_ml_client.models.get(teacher_embedding_model_name, label=\"latest\")\n",
    "print(f\"Found model {teacher_embedding_model_name} in registry {embedding_registry_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/\".join(model.id.split(\"/\")[:-2])\n",
    "model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model as a serverless endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"{model.name}\".replace(\".\", \"-\").replace(\"_\", \"-\")[:64]\n",
    "print(f\"Deploying model {model.name} as endpoint {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "endpoint_base_url = os.getenv(\"EMBEDDING_AZURE_OPENAI_ENDPOINT\")\n",
    "endpoint_api_key = os.getenv(\"EMBEDDING_AZURE_OPENAI_API_KEY\")\n",
    "endpoint_deployment_name = os.getenv(\"EMBEDDING_AZURE_OPENAI_DEPLOYMENT\")\n",
    "endpoint_api_version = os.getenv(\"EMBEDDING_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if endpoint_base_url:\n",
    "    print(f\"Skipping endpoint deployment as an existing embedding model completion endpoint was provided {endpoint_base_url}\")\n",
    "else:\n",
    "\n",
    "    from azure.core.exceptions import ResourceNotFoundError\n",
    "    try:\n",
    "        serverless_endpoint = client.serverless_endpoints.get(endpoint_name)\n",
    "        print(f\"Found existing endpoint {endpoint_name}\")\n",
    "    except ResourceNotFoundError as ex:\n",
    "        serverless_endpoint = ServerlessEndpoint(name=endpoint_name, model_id=model_id)\n",
    "        serverless_endpoint = client.serverless_endpoints.begin_create_or_update(serverless_endpoint).result()\n",
    "\n",
    "        print(\"Waiting for deployment to complete...\")\n",
    "        serverless_endpoint = ServerlessEndpoint(name=endpoint_name, model_id=model_id)\n",
    "\n",
    "        created_endpoint = client.serverless_endpoints.begin_create_or_update(serverless_endpoint).result()\n",
    "        print(\"Deployment complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the endpoint URL, name and keys and store them in the shared state to pass on to the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not endpoint_base_url:\n",
    "\n",
    "    endpoint = client.serverless_endpoints.get(endpoint_name)\n",
    "    endpoint_keys = client.serverless_endpoints.get_keys(endpoint_name)\n",
    "\n",
    "    # Update the shared `.env.state` env file with the newly deployed finetuned model endpoint\n",
    "    from utils import update_state\n",
    "\n",
    "    endpoint_base_url = endpoint.scoring_uri\n",
    "    endpoint_api_key = endpoint_keys.primary_key\n",
    "    endpoint_deployment_name = endpoint.name\n",
    "\n",
    "    update_state(\"EMBEDDING_AZURE_OPENAI_ENDPOINT\", endpoint_base_url)\n",
    "    update_state(\"EMBEDDING_AZURE_OPENAI_API_KEY\", endpoint_api_key)\n",
    "    update_state(\"EMBEDDING_AZURE_OPENAI_DEPLOYMENT\", endpoint_deployment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the embedding model is deployed and available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "oai_client = AzureOpenAI(\n",
    "  api_key = endpoint_api_key,\n",
    "  api_version = endpoint_api_version,\n",
    "  azure_endpoint = endpoint_base_url\n",
    ")\n",
    "\n",
    "oai_client.embeddings.create(input = [\"Hello\"], model=endpoint_deployment_name).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
