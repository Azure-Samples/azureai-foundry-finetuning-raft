{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a fine-tuned model with Model-As-Service Serverless\n",
    "\n",
    "This notebook shows how to deploy a fine-tuned model serverless on Azure AI Model-As-Service.\n",
    "\n",
    "**Note**: It waits for the fine-tuned model to be available so it is safe running it before the fine-tuning job has completed.\n",
    "\n",
    "#### Model\n",
    "We will use the model fine-tuned in the previous [2_finetune.ipynb](./2_finetune.ipynb) notebook.\n",
    "\n",
    "#### Pre-requisites\n",
    "Same as in the [1_gen.ipynb](./1_gen.ipynb) notebook, you need to subscribe to the Marketplace offering. This should be done already but here is the [documentation](https://aka.ms/raft-llama-31-learn-deploy-405b) in case you worked around this in the previous notebook.\n",
    "\n",
    "The requirements should have been automatically installed if you opened the project in Dev Container or Codespaces, but if not, uncomment the following cell to install the requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ./config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "from azure.ai.ml.entities import MarketplaceSubscription, ServerlessEndpoint\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    client = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    print(\"Please create a workspace configuration file in the current directory.\")\n",
    "\n",
    "# Get AzureML workspace object.\n",
    "workspace = client._workspaces.get(client.workspace_name)\n",
    "workspace_id = workspace._workspace_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out the name of the finetuned model from the shared state environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Variables passed by previous notebooks\n",
    "load_dotenv(\".env.state\")\n",
    "\n",
    "FINETUNED_MODEL_NAME = os.getenv(\"FINETUNED_MODEL_NAME\")\n",
    "FINETUNED_MODEL_FORMAT = os.getenv(\"FINETUNED_MODEL_FORMAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine-tuning job might still be training so let's wait until the model is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for fine tuned model ft-job-finetune-registered-3838 to complete training...\n",
      "Model ft-job-finetune-registered-3838 is ready\n"
     ]
    }
   ],
   "source": [
    "from utils import wait_for_model\n",
    "\n",
    "print(f\"Waiting for fine tuned model {FINETUNED_MODEL_NAME} to complete training...\")\n",
    "model = wait_for_model(client, FINETUNED_MODEL_NAME)\n",
    "print(f\"Model {FINETUNED_MODEL_NAME} is ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's subscribe to the model, this requires having accepted the provider's Marketplace terms at least once in the Model Catalog UI before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subscribing to Meta-Llama-3-1-8B-Instruct for model ID azureml://registries/azureml-meta/models/Meta-Llama-3.1-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "base_model_id = model.properties[\"baseModelId\"]\n",
    "model_id = model.id\n",
    "subscription_name = base_model_id.split(\"/\")[-1].replace(\".\", \"-\").replace(\"_\", \"-\")\n",
    "print(f\"Subscribing to {subscription_name} for model ID {base_model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Asset ID required to deploy the model is not currently exposed through the Python SDK so we're constructing it using the information we have on hand.\n",
    "\n",
    "**Note**: as we're indirectly constructing the Asset ID blob storage path, the backend might change this and break this code. If this happens, you can figure out what the new expected form is by searching for the Asset ID field in the fine-tuned model's catalog page and adjust the template bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model asset id azureml://locations/westus3/workspaces/34e2a898-050c-49d7-ae9c-5f7cba2249ee/models/ft-job-finetune-registered-3838/versions/2\n"
     ]
    }
   ],
   "source": [
    "model_asset_id = f\"azureml://locations/westus3/workspaces/{workspace_id}/{\"/\".join(model.id.split('/')[9:])}\"\n",
    "print(f\"Deploying model asset id {model_asset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class MarketplaceSubscription: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Method marketplace_subscriptions: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Method begin_create_or_update: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "ActivityCompleted: Activity=MarketplaceSubscription.BeginCreateOrUpdate, HowEnded=Failure, Duration=867.38 [ms], Exception=ResourceExistsError, ErrorCategory=UserError, ErrorMessage=(UserError) Marketplace subscription with name [Meta-Llama-3-1-8B-Instruct-subscription] already exists for Workspace name [ai-project-otgsljc2twqys] and ModelId [azureml://registries/azureml-meta/models/Meta-Llama-3.1-8B-Instruct].\n",
      "Code: UserError\n",
      "Message: Marketplace subscription with name [Meta-Llama-3-1-8B-Instruct-subscription] already exists for Workspace name [ai-project-otgsljc2twqys] and ModelId [azureml://registries/azureml-meta/models/Meta-Llama-3.1-8B-Instruct].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marketplace subscription Meta-Llama-3-1-8B-Instruct already exists for model azureml://registries/azureml-meta/models/Meta-Llama-3.1-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "from azure.core.exceptions import ResourceExistsError\n",
    "marketplace_subscription = MarketplaceSubscription(\n",
    "    model_id=base_model_id,\n",
    "    name=subscription_name,\n",
    ")\n",
    "\n",
    "try:\n",
    "    marketplace_subscription = client.marketplace_subscriptions.begin_create_or_update(marketplace_subscription).result()\n",
    "except ResourceExistsError as ex:\n",
    "    print(f\"Marketplace subscription {subscription_name} already exists for model {base_model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model as a serverless endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model ft-job-finetune-registered-3838 as endpoint ft-job-finetune-registered-3838\n"
     ]
    }
   ],
   "source": [
    "# The endpoint name is deterministic based only on the model name which is assumed to contain a hash of the dataset \n",
    "# because if the finetuned model for that specific dataset is already deployed, we don't want to deploy it again\n",
    "endpoint_name = f\"{model.name}\".replace(\".\", \"-\").replace(\"_\", \"-\")[:64]\n",
    "print(f\"Deploying model {model.name} as endpoint {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing endpoint ft-job-finetune-registered-3838\n"
     ]
    }
   ],
   "source": [
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "try:\n",
    "    serverless_endpoint = client.serverless_endpoints.get(endpoint_name)\n",
    "    print(f\"Found existing endpoint {endpoint_name}\")\n",
    "except ResourceNotFoundError as ex:\n",
    "    serverless_endpoint = ServerlessEndpoint(name=endpoint_name, model_id=model_asset_id)\n",
    "    serverless_endpoint = client.serverless_endpoints.begin_create_or_update(serverless_endpoint).result()\n",
    "\n",
    "    print(\"Waiting for deployment to complete...\")\n",
    "    serverless_endpoint = ServerlessEndpoint(name=endpoint_name, model_id=model_id)\n",
    "\n",
    "    created_endpoint = client.serverless_endpoints.begin_create_or_update(serverless_endpoint).result()\n",
    "    print(\"Deployment complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the endpoint URL, name and keys and store them in the shared state to pass on to the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Method get_keys: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating state file with FINETUNED_OPENAI_BASE_URL=https://ft-job-finetune-registered-3838.westus3.models.ai.azure.com\n",
      "Updating state file with FINETUNED_OPENAI_API_KEY=zd0B****************************\n",
      "Updating state file with FINETUNED_OPENAI_DEPLOYMENT=ft-job-finetune-registered-3838\n"
     ]
    }
   ],
   "source": [
    "endpoint = client.serverless_endpoints.get(endpoint_name)\n",
    "endpoint_keys = client.serverless_endpoints.get_keys(endpoint_name)\n",
    "\n",
    "# Update the shared `.env.state` env file with the newly deployed finetuned model endpoint\n",
    "from utils import update_state\n",
    "\n",
    "update_state(\"FINETUNED_OPENAI_BASE_URL\", endpoint.scoring_uri)\n",
    "update_state(\"FINETUNED_OPENAI_API_KEY\", endpoint_keys.primary_key)\n",
    "update_state(\"FINETUNED_OPENAI_DEPLOYMENT\", endpoint.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the finetuned model is deployed and available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing deployed chat model at https://ft-job-finetune-registered-3838.westus3.models.ai.azure.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'message': {'content': \"What a broad and exciting question! I can provide information on a wide range of topics, but my knowledge is based on my training data, which is current up to 2021. Here's a summary of what I know:\\n\\n**General Knowledge**: I have a vast understanding of general knowledge, including but not limited to:\\n\\n* History: Events, figures, and timelines from ancient to modern times\\n* Science: Physics, biology, chemistry, astronomy, and more\\n* Technology: Computing, internet, software, hardware, and emerging technologies\\n* Geography: Countries, cities, mountains, rivers, and other geographical features\\n* Culture: Arts, literature, music, and cultural practices\\n* Language: Grammar, vocabulary, and language-related topics\\n\\n**Math and Logic**: I'm familiar with mathematical concepts and can perform calculations, including:\\n\\n* Basic arithmetic operations (addition, subtraction, multiplication, division)\\n* Algebra: Equations, functions, and graphing\\n* Geometry: Points, lines, angles, and shapes\\n* Trigonometry: Triangles, angles, and wave patterns\\n* Logic: Propositional and predicate logic, and basic set theory\\n\\n**Computing and Programming**: I have knowledge of various programming languages, including:\\n\\n* Python: Syntax, data structures, and popular libraries\\n* Java: Object-oriented programming, syntax, and standard libraries\\n* C++: Syntax, data structures, and standard libraries\\n* Web development: HTML, CSS, JavaScript, and frameworks like React and Angular\\n* Database management: SQL, database design, and query optimization\\n\\n**Other topics**: I can also provide information on topics like:\\n\\n* Business: Management, finance, marketing, and entrepreneurship\\n* Health and wellness: Nutrition, fitness, mental health, and medicine\\n* Sports: Rules, strategies, and notable athletes\\n* Education: Academic disciplines, teaching methods, and educational technology\\n\\nPlease keep in mind that my knowledge is based on my training data and may not be up-to-date or exhaustive on all topics. If you have a specific question or topic in mind, feel free to ask, and I'll do my best to provide a helpful response!\",\n",
       "    'role': 'assistant',\n",
       "    'tool_calls': []}}],\n",
       " 'created': 1726247452,\n",
       " 'id': 'cmpl-37a2b1e3506146ddb39e6598722e50f5',\n",
       " 'model': 'Meta-Llama-3.1-8B-Instruct',\n",
       " 'object': 'chat.completion',\n",
       " 'usage': {'completion_tokens': 437, 'prompt_tokens': 15, 'total_tokens': 452}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "print(f\"Testing deployed {FINETUNED_MODEL_FORMAT} model at {endpoint.scoring_uri}\")\n",
    "url = f\"{endpoint.scoring_uri}/v1/completions\" if FINETUNED_MODEL_FORMAT == \"completion\" else f\"{endpoint.scoring_uri}/v1/chat/completions\"\n",
    "\n",
    "prompt = \"What do you know?\"\n",
    "payload = {\"max_tokens\": 1024, \"prompt\": [prompt]} if FINETUNED_MODEL_FORMAT == \"completion\" else {\n",
    "    \"messages\":[ { \"role\":\"user\",\"content\":prompt } ],\n",
    "    \"max_tokens\":1024\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": endpoint_keys.primary_key}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
