{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a fine-tuned model with Model-As-Service Serverless\n",
    "\n",
    "This notebook shows how to deploy a fine-tuned model serverless on Azure AI Model-As-Service.\n",
    "\n",
    "**Note**: It waits for the fine-tuned model to be available so it is safe running it before the fine-tuning job has completed.\n",
    "\n",
    "#### Model\n",
    "We will use the model fine-tuned in the previous [2_finetune.ipynb](./2_finetune.ipynb) notebook.\n",
    "\n",
    "#### Pre-requisites\n",
    "- Same as in the [1_gen.ipynb](./1_gen.ipynb) notebook, you need to subscribe to the Marketplace offering. This should be done already but here is the [documentation](https://aka.ms/raft-llama-31-learn-deploy-405b) in case you worked around this in the previous notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "from azure.ai.ml.entities import MarketplaceSubscription, ServerlessEndpoint\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    client = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    print(\"Please create a workspace configuration file in the current directory.\")\n",
    "\n",
    "# Get AzureML workspace object.\n",
    "workspace = client._workspaces.get(client.workspace_name)\n",
    "workspace_id = workspace._workspace_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Meta Llama 3.1 405B Instruct as the teacher model to generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "teacher_model_name: str = \"Meta-Llama-3.1-405B-Instruct\"\n",
    "registry_name: str = \"azureml-meta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_ml_client = MLClient(credential, registry_name=registry_name)\n",
    "\n",
    "print(f\"Searching for model {teacher_model_name}\")\n",
    "model = registry_ml_client.models.get(teacher_model_name, label=\"latest\")\n",
    "print(f\"Found model {teacher_model_name} in registry {registry_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's subscribe to the model, this requires having accepted the provider's Marketplace terms at least once in the Model Catalog UI before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_name = teacher_model_name.replace(\".\", \"-\").replace(\"_\", \"-\")\n",
    "model_id = \"/\".join(model.id.split(\"/\")[:-2])\n",
    "print(f\"Subscribing to {subscription_name} for model ID {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.exceptions import ResourceExistsError\n",
    "marketplace_subscription = MarketplaceSubscription(\n",
    "    model_id=model_id,\n",
    "    name=subscription_name,\n",
    ")\n",
    "\n",
    "try:\n",
    "    marketplace_subscription = client.marketplace_subscriptions.begin_create_or_update(marketplace_subscription).result()\n",
    "except ResourceExistsError as ex:\n",
    "    print(f\"Marketplace subscription {subscription_name} already exists for model {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model as a serverless endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "endpoint_name = f\"{model.name}-raft\".replace(\".\", \"-\").replace(\"_\", \"-\")[:64]\n",
    "print(f\"Deploying model {model.name} as endpoint {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "try:\n",
    "    serverless_endpoint = client.serverless_endpoints.get(endpoint_name)\n",
    "    print(f\"Found existing endpoint {endpoint_name}\")\n",
    "except ResourceNotFoundError as ex:\n",
    "    serverless_endpoint = ServerlessEndpoint(name=endpoint_name, model_id=model_id)\n",
    "    serverless_endpoint = client.serverless_endpoints.begin_create_or_update(serverless_endpoint).result()\n",
    "\n",
    "    print(\"Waiting for deployment to complete...\")\n",
    "    serverless_endpoint = ServerlessEndpoint(name=endpoint_name, model_id=model_id)\n",
    "\n",
    "    created_endpoint = client.serverless_endpoints.begin_create_or_update(serverless_endpoint).result()\n",
    "    print(\"Deployment complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the endpoint URL, name and keys and store them in the shared state to pass on to the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = client.serverless_endpoints.get(endpoint_name)\n",
    "endpoint_keys = client.serverless_endpoints.get_keys(endpoint_name)\n",
    "\n",
    "# Update the shared `.env.state` env file with the newly deployed finetuned model endpoint\n",
    "from utils import update_state\n",
    "\n",
    "update_state(\"COMPLETION_OPENAI_BASE_URL\", endpoint.scoring_uri)\n",
    "update_state(\"COMPLETION_OPENAI_API_KEY\", endpoint_keys.primary_key)\n",
    "update_state(\"COMPLETION_OPENAI_DEPLOYMENT\", endpoint.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the teacher model is deployed and available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"{endpoint.scoring_uri}/v1/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"messages\":[ { \"role\":\"user\",\"content\":\"What do you know?\" } ],\n",
    "    \"max_tokens\":1024\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": endpoint_keys.primary_key}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
